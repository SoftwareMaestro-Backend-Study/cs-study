### 배경

- 기존에는 프로세스가 실행되는 코드의 전체를 메모리에 로드해야 했고, 메모리 용량보다 더 큰 프로그램은 실행시킬 수 없었다.
- 하지만 실제로는 코드의 일부에서만 대부분의 시간을 사용하고, 프로세스는 특정 순간에는 항상 작은 양의 주소 공간을 사용했기 때문에 이러한 방식은 매우 비효율적이었다.

### 가상 메모리

- 가상 메모리란?
    - 물리적 메모리 크기의 한계를 극복하기 위해 나온 기술
    - 프로세스를 실행할 때 실행에 필요한 일부만 메모리에 로드하고 나머지는 디스크에 두는 것
    - 결과적으로 메모리에 작은 양의 주소 공간만 있으면 충분히 프로세스를 수행할 수 있고, 그에 따라 더 많은 프로그램을 동시에 실행할 수 있게 된다.
    - Demand Paging : 현재 필요한 page만 메모리에 올리는 것
- 페이지 교체 알고리즘
    - 빈 프레임이 없을 경우 희생 당할 프레임(victim frame)을 고르는 알고리즘\
    - OPT (Optimal Algorithm)
        - 가장 먼 미래에 참조되는 page를 대체하는 방법
        - 항상 최적의 결과를 갖는다.
        - 미래의 참조를 모두 알고 있어야 하므로 실제로 사용하기는 아렵고, 다른 알고리즘의 성능에 대한 upper bound를 제공한다. 연구 목적으로 사용된다.
    - FIFO (First In First Out)
        - 제일 먼저 들어온 것을 먼저 내쫓는 방법
        - 모든 page에 대해서 평등하고, 구현하기 쉽다.
        - but, 어떤 page는 항상 필요할 수 있는데, 그런 경우에도 replace가 되는 단점이 있다.
        - frame이 늘어나도 page fault가 감소하지 않고 오히려 늘어나는 경우가 존재 = Belady’s anomaly
        
        <img width="563" alt="image" src="https://github.com/SoftwareMaestro-Backend-Study/cs-study/assets/71378475/ecf6c358-a2e6-46d9-907a-c2595e0e8773">

    - LRU (Least Recently Used)
        - 가장 오래전에 참조된 것을 지우는 방법 (Optimal에 근접)
        - Belady’s anomaly가 발생하지 않는다.
        - but, 구현하기 어렵고, 접근되는 빈도를 고려하지 않는 단점이 있다.
        
        <img width="675" alt="image" src="https://github.com/SoftwareMaestro-Backend-Study/cs-study/assets/71378475/6b211106-6f8e-488f-bffa-8f79030b18d2">

    - LFU (Least Frequently Used)
        - 참조 횟수가 가장 적은 page를 지우는 방법
        - LRU에 비해 장기적인 시간 규모를 보기 때문에 page의 인기도를 조금 더 정확히 반영할 수 있지만, 최근성은 반영하지 못한다.
        - 힙(heap)을 사용하여, 최소 빈도를 갖는 page를 찾거나 삽입, 삭제하는데 ****O(logn)의 시간이 걸리게 되므로 훨씬 효율적이다.
    - Second Chance Algorithm (Clock Algorithm)
        - LRU와 LFU는 실제로 paging system에서 사용할 수 있을까 ? X
            - LRU와 LFU의 알고리즘 구현에서 운영체제가 자료구조를 변경하고 유지하는 작업을 수행해야 하는데, 이미 메모리에 page가 올라가 있는 경우에는 CPU가 운영체제에 넘어가지 않는다. page fault가 발생해야 CPU가 운영체제에 넘어가고, 디스크에서 메모리로 page를 로드할 때 해당 page에 대한 정보를 얻고 갱신할 수 있다.
            - 따라서 운영체제가 참조한 지 오래되거나 참조 횟수가 적은 페이지를 정확하게 알 수 없다.
        - Second Chance Algorithm은 LRU의 근사 알고리즘으로, 최근에 참조되었는지 여부를 나태내는 Reference bit이라는 정보를 사용
        - Reference bit가 0인 것을 찾을 때까지 시계처럼 한 바퀴씩 포인터를 이동하다가 0인 것을 찾으면 해당 page를 교체하는 방식이다. 만약 Reference bit가 1인 page를 만나면 0으로 바꿔주고, 한 바퀴 되돌아와서도(Second Chance) 여전히 0이면 해당 page를 교체한다. 다시 bit가 1로 바뀌어있다면 그만큼 자주 사용되는 page라는 의미인 것이다.
        
        <img width="634" alt="image" src="https://github.com/SoftwareMaestro-Backend-Study/cs-study/assets/71378475/bdb62583-ac05-4f3a-ab92-23139193aa1f">


### Thrashing

- 프로세스가 원활한 수행에 필요한 최소한의 page frame을 할당받지 못해서, 실행보다 Swapping 하는데 더 많은 시간을 소모하는 현상
- 동작 과정
1. page가 부족하여 page fault가 증가한다.
2. Swapping(I/O) 작업이 증가하여 CPU 효율성(Utilization)이 감소한다.
3. OS는 Multiprogramming Degree를 높여야 한다고 판단하여 또 다른 프로세스를 시스템에 추가한다.
4. 프로세스당 할당된 page frame이 더욱 감소하여 page fault가 더 증가한다.
5. 프로세스는 Swapping으로 인해 매우 바빠져서 대부분의 시간에 CPU는 한가해진다.
    

- Thrashing Prevention
    - 프로세스에게 frame을 필요한 만큼 많이 제공해야 한다.
    - 그렇다면, 어떻게 프로세스가 필요한 frame의 양을 알 수 있을까?
    1. Working-Set Model
        - Working Set Model
            - 가능한 최대 Multiprogramming Degree를 유지하면서 Thrashing을 막는 방법
            - 참조 지역성 원리를 통해 프로세스가 일정 시간 동안 원할히 수행되기 위해 한꺼번에 메모리에 올라와있어야 하는 page들의 집합을 말한다.
            - 운영체제가 지속적으로 각 프로세스의 Working set을 지켜보면서,
                
                충분한 frame을 할당해주고, 가장 최근 윈도우에서 프로세스가 참조한 page의 총 개수가 사용 가능한 frame 수보다 크다면 프로세스 중에서 하나를 종료시키고 해당 프로세스의 frame을 다른 프로세스들에게 할당한다.
                
    2. PFF Sheme
        - page fault의 상한 값과 하한 값을 두고, page fault rate가 상한 값을 넘으면 frame을 더 할당하고, 하한 값보다 낮아지면 할당된 frame 수를 줄이는 방법
